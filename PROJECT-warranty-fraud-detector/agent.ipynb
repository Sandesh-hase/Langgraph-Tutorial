{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0da140b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import TypedDict, Dict, Any\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb11d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small demo claims CSV (3 rows only)\n",
    "claims_df = pd.read_csv(\"data/warranty_claims.csv\")\n",
    "\n",
    "# Load the expanded policy manual PDF\n",
    "loader = PyPDFLoader(\"data/AutoDrive_Warranty_Policy_2025.pdf\")\n",
    "policy_docs = loader.load()\n",
    "policy_text = \" \".join([doc.page_content for doc in policy_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a2a130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>model</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>days_since_purchase</th>\n",
       "      <th>mileage</th>\n",
       "      <th>part_replaced</th>\n",
       "      <th>part_cost</th>\n",
       "      <th>labor_cost</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>invoice_present</th>\n",
       "      <th>image_present</th>\n",
       "      <th>previous_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLM-DEMO-1</td>\n",
       "      <td>Volt-X (Four-Wheeler, EV Sedan)</td>\n",
       "      <td>8/8/2024</td>\n",
       "      <td>5/24/2025</td>\n",
       "      <td>289</td>\n",
       "      <td>7363</td>\n",
       "      <td>Headlight</td>\n",
       "      <td>231</td>\n",
       "      <td>199</td>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     claim_id                            model purchase_date claim_date  \\\n",
       "0  CLM-DEMO-1  Volt-X (Four-Wheeler, EV Sedan)      8/8/2024  5/24/2025   \n",
       "\n",
       "   days_since_purchase  mileage part_replaced  part_cost  labor_cost  \\\n",
       "0                  289     7363     Headlight        231         199   \n",
       "\n",
       "   total_cost  invoice_present  image_present  previous_claims  \n",
       "0         430                1              1                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b22fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AutoDrive Motors Pvt. Ltd.\\nWarranty Claims Policy Manual\\nEffective Date: January 1, 2025\\nVersion: 1.2\\n1. Documentation Requirements\\n- Every warranty claim must include:\\n- A valid invoice copy with purchase date, VIN, and customer ID.\\n- At least one supporting image (part photo, repair slip).\\n- Service center job card when applicable.\\n- Claims without documentation must be escalated for manual review.\\n2. Warranty Coverage\\n- Four-Wheelers: 365 days OR 20,000 km (whichever comes first).\\n- Two-Wheelers: 180 days OR 10,000 km (whichever comes first).\\n- Only claims for original manufacturer parts are considered valid.\\n3. Covered Parts\\n- Four-Wheelers: Brake Pad, Airbag, Fuel Pump, Battery, Sensor, ECU, Alternator.\\n- Two-Wheelers: Brake Pad, Battery, Sensor, Headlight, Starter Motor.\\nExclusions:\\n- Paint, upholstery, glass, wipers, and other wear-and-tear items.\\n- Accidental damage or unauthorized modifications.\\n4. Labor & Cost Guidelines\\n- Labor cost per claim should not exceed $250 for two-wheelers and $500 for four-wheelers.\\n- Claims exceeding $1000 in total cost must be escalated for management approval.\\n- Any claim filed within 30 days of purchase with cost greater than $500 is suspicious.\\n5. Fraud Indicators - Customers with 3 or more prior claims must be flagged.\\n- Dealers with abnormally high claim ratios should be investigated.\\n- Expired warranties (time or mileage exceeded) are invalid.\\n- Missing invoice OR mismatched VIN is treated as potential fraud.\\n6. Escalation Rules\\n- Claims exceeding the above thresholds (labor/cost/coverage) must be escalated to HITL.\\n- Any borderline case (uncertain coverage, ambiguous evidence) must be escalated.\\n- HITL reviewer has final authority to approve or reject. AutoDrive Motors Pvt. Ltd. | Confidential - For Internal Use Only'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8afeee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"gpt-4o\",   # Change to your Azure GPT-4 deployment name\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0c8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaimState(TypedDict):\n",
    "    claim: Dict[str, Any]\n",
    "    policy_check: str\n",
    "    fraud_score: float\n",
    "    evidence: str\n",
    "    decision: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "091b935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Policy Check Agent (structured validation via PDF rules)\n",
    "def policy_check_agent(state: ClaimState) -> ClaimState:\n",
    "    claim = state[\"claim\"]\n",
    "    vtype = \"Four-Wheeler\" if \"Four-Wheeler\" in claim[\"model\"] else \"Two-Wheeler\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a warranty compliance officer. \n",
    "    Policy manual:\n",
    "    {policy_text}\n",
    "    \n",
    "    Vehicle type: {vtype}\n",
    "    Claim details: {claim}\n",
    "    \n",
    "    Based on warranty days, mileage, and covered parts,\n",
    "    is this claim covered under the policy? \n",
    "    Answer with: \"Covered by policy\" or \"Not covered by policy\".\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    state[\"policy_check\"] = response.content.strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "# 2. Fraud Scoring Agent\n",
    "def fraud_scoring_agent(state: ClaimState) -> ClaimState:\n",
    "    claim = state[\"claim\"]\n",
    "    prompt = f\"\"\"\n",
    "    You are a fraud detection expert.\n",
    "    Policy manual:\n",
    "    {policy_text}\n",
    "    \n",
    "    Claim details:\n",
    "    {claim}\n",
    "    Policy validation: {state['policy_check']}\n",
    "    \n",
    "    Analyze whether this claim looks fraudulent.\n",
    "    Return ONLY a number between 0 and 1 (fraud likelihood score).\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        score = float(response.content.strip())\n",
    "    except:\n",
    "        score = 0.5\n",
    "    state[\"fraud_score\"] = score\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# 3. Evidence Collector Agent\n",
    "def evidence_collector_agent(state: ClaimState) -> ClaimState:\n",
    "    claim = state[\"claim\"]\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with collecting evidence for claim review.\n",
    "    Policy manual:\n",
    "    {policy_text}\n",
    "    \n",
    "    Claim details:\n",
    "    {claim}\n",
    "    Fraud score: {state['fraud_score']}\n",
    "    \n",
    "    Compare claim against the policy manual and fraud indicators.\n",
    "    List any red flags or violations found. If none, say \"No issues\".\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    state[\"evidence\"] = response.content.strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "def action_agent(state: ClaimState) -> ClaimState:\n",
    "    # Prefer an LLM-informed final decision that considers previous agents' outputs.\n",
    "    # Build a compact prompt summarizing the claim and previous agent outputs.\n",
    "    claim = state.get(\"claim\", {})\n",
    "    policy_check = state.get(\"policy_check\", \"\")\n",
    "    fraud_score = state.get(\"fraud_score\", 0.0)\n",
    "    evidence = state.get(\"evidence\", \"\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a warranty adjudicator. Given the following information about a warranty claim, choose one of three actions: \"Approve claim\", \"Reject claim\", or \"Escalate to HITL\" (human-in-the-loop for manual review).\n",
    "\n",
    "    Provide your answer as a single decision on the first line, and then a short (1-2 sentence) justification on the following line.\n",
    "\n",
    "    Policy manual (for reference):\n",
    "    {policy_text}\n",
    "\n",
    "    Claim details: {claim}\n",
    "\n",
    "    Policy check result: {policy_check}\n",
    "    Fraud score (0-1): {fraud_score}\n",
    "    Evidence / red flags found: {evidence}\n",
    "\n",
    "    Important: If the policy_check indicates the claim is \"Not covered by policy\" or the evidence highlights a direct policy violation (e.g., part not covered), prefer \"Reject claim\" unless strong justification exists to approve. If the evidence is ambiguous, but fraud score is moderately high (>0.5), choose \"Escalate to HITL\".\n",
    "    \"\"\"\n",
    "\n",
    "    decision_text = \"\"\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        res_text = response.content.strip()\n",
    "        # Try to parse the first line as the decision\n",
    "        first_line = res_text.splitlines()[0].strip()\n",
    "        normalized = first_line.lower()\n",
    "        if \"approve\" in normalized:\n",
    "            decision_text = \"Approve claim\"\n",
    "        elif \"reject\" in normalized:\n",
    "            decision_text = \"Reject claim\"\n",
    "        elif \"escalate\" in normalized or \"hitl\" in normalized or \"human\" in normalized:\n",
    "            decision_text = \"Escalate to HITL\"\n",
    "        else:\n",
    "            # If parsing fails, fall back to rule-based decision\n",
    "            decision_text = \"\"\n",
    "\n",
    "        # Record the full LLM response in the trace\n",
    "        state.setdefault(\"trace\", []).append({\n",
    "            \"agent\": \"action_agent\",\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": res_text,\n",
    "        })\n",
    "    except Exception:\n",
    "        # LLM failed — leave res_text empty and fall back\n",
    "        res_text = \"\"\n",
    "\n",
    "    # If LLM didn't produce a clear decision, use conservative rule-based fallback\n",
    "    if not decision_text:\n",
    "        if policy_check == \"Not covered by policy\":\n",
    "            decision_text = \"Reject claim\"\n",
    "        elif fraud_score > 0.5:\n",
    "            decision_text = \"Escalate to HITL\"\n",
    "        else:\n",
    "            decision_text = \"Approve claim\"\n",
    "\n",
    "        # record fallback decision step in trace (clear about being rule-based)\n",
    "        state.setdefault(\"trace\", []).append({\n",
    "            \"agent\": \"action_agent\",\n",
    "            \"prompt\": \"(rule-based fallback)\",\n",
    "            \"response\": decision_text,\n",
    "        })\n",
    "\n",
    "    state[\"decision\"] = decision_text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df06d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ClaimState)\n",
    "\n",
    "graph.add_node(\"PolicyCheck\", policy_check_agent)\n",
    "graph.add_node(\"FraudScoring\", fraud_scoring_agent)\n",
    "graph.add_node(\"EvidenceCollector\", evidence_collector_agent)\n",
    "graph.add_node(\"Action\", action_agent)\n",
    "\n",
    "graph.set_entry_point(\"PolicyCheck\")\n",
    "graph.add_edge(\"PolicyCheck\", \"FraudScoring\")\n",
    "graph.add_edge(\"FraudScoring\", \"EvidenceCollector\")\n",
    "graph.add_edge(\"EvidenceCollector\", \"Action\")\n",
    "graph.add_edge(\"Action\", END)\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ca1006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "---\n",
       "config:\n",
       "  flowchart:\n",
       "    curve: linear\n",
       "---\n",
       "graph TD;\n",
       "\t__start__([<p>__start__</p>]):::first\n",
       "\tPolicyCheck(PolicyCheck)\n",
       "\tFraudScoring(FraudScoring)\n",
       "\tEvidenceCollector(EvidenceCollector)\n",
       "\tAction(Action)\n",
       "\t__end__([<p>__end__</p>]):::last\n",
       "\tEvidenceCollector --> Action;\n",
       "\tFraudScoring --> EvidenceCollector;\n",
       "\tPolicyCheck --> FraudScoring;\n",
       "\t__start__ --> PolicyCheck;\n",
       "\tAction --> __end__;\n",
       "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
       "\tclassDef first fill-opacity:0\n",
       "\tclassDef last fill:#bfb6fc\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Get the Mermaid code\n",
    "mermaid_code = app.get_graph().draw_mermaid()\n",
    "\n",
    "# Display in Jupyter\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14890f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for idx, row in claims_df.iterrows():\n",
    "    state = app.invoke({\"claim\": row.to_dict()})\n",
    "    results.append({\n",
    "        \"claim_id\": row[\"claim_id\"],\n",
    "        \"model\": row[\"model\"],\n",
    "        \"decision\": state[\"decision\"],\n",
    "        \"policy_check\": state[\"policy_check\"],\n",
    "        \"fraud_score\": state[\"fraud_score\"],\n",
    "        \"evidence\": state[\"evidence\"]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# print(results_df)\n",
    "\n",
    "# # Save to CSV if needed\n",
    "# results_df.to_csv(\"demo_claims_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4c18bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decision</th>\n",
       "      <th>policy_check</th>\n",
       "      <th>fraud_score</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLM-DEMO-1</td>\n",
       "      <td>Volt-X (Four-Wheeler, EV Sedan)</td>\n",
       "      <td>Escalate to HITL</td>\n",
       "      <td>**Not covered by policy**  \\n\\nExplanation: Th...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>### Claim Review for Claim ID: CLM-DEMO-1\\n\\n#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     claim_id                            model          decision  \\\n",
       "0  CLM-DEMO-1  Volt-X (Four-Wheeler, EV Sedan)  Escalate to HITL   \n",
       "\n",
       "                                        policy_check  fraud_score  \\\n",
       "0  **Not covered by policy**  \\n\\nExplanation: Th...          0.2   \n",
       "\n",
       "                                            evidence  \n",
       "0  ### Claim Review for Claim ID: CLM-DEMO-1\\n\\n#...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c62fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': {'claim_id': 'CLM-DEMO-1',\n",
       "  'model': 'Volt-X (Four-Wheeler, EV Sedan)',\n",
       "  'purchase_date': '8/8/2024',\n",
       "  'claim_date': '5/24/2025',\n",
       "  'days_since_purchase': 289,\n",
       "  'mileage': 7363,\n",
       "  'part_replaced': 'Headlight',\n",
       "  'part_cost': 231,\n",
       "  'labor_cost': 199,\n",
       "  'total_cost': 430,\n",
       "  'invoice_present': 1,\n",
       "  'image_present': 1,\n",
       "  'previous_claims': 1},\n",
       " 'policy_check': '**Not covered by policy**  \\n\\nExplanation: The part replaced in this claim is a **Headlight**, which is not listed as a covered part for Four-Wheelers under the warranty policy.',\n",
       " 'fraud_score': 0.2,\n",
       " 'evidence': '### Claim Review for Claim ID: CLM-DEMO-1\\n\\n#### **Comparison Against Policy Manual**\\n\\n1. **Documentation Requirements**:\\n   - **Invoice Present**: Yes (Valid as per policy).\\n   - **Supporting Image**: Yes (Valid as per policy).\\n   - **Service Center Job Card**: Not mentioned, but not explicitly required for this claim.\\n   - **Conclusion**: No issues with documentation.\\n\\n2. **Warranty Coverage**:\\n   - **Vehicle Type**: Four-Wheeler (Volt-X, EV Sedan).\\n   - **Warranty Period**: 365 days OR 20,000 km (whichever comes first).\\n   - **Claim Date**: 5/24/2025 (289 days since purchase, within 365-day limit).\\n   - **Mileage**: 7,363 km (within 20,000 km limit).\\n   - **Conclusion**: Warranty coverage is valid.\\n\\n3. **Covered Parts**:\\n   - **Part Replaced**: Headlight.\\n   - **Four-Wheelers Covered Parts**: Headlight is **not listed** as a covered part for four-wheelers (only listed for two-wheelers).\\n   - **Conclusion**: **Violation** - Headlight is not covered under warranty for four-wheelers.\\n\\n4. **Labor & Cost Guidelines**:\\n   - **Labor Cost**: $199 (within $500 limit for four-wheelers).\\n   - **Total Cost**: $430 (below $1000 threshold for management approval).\\n   - **Conclusion**: No issues with labor or cost.\\n\\n5. **Fraud Indicators**:\\n   - **Previous Claims**: 1 prior claim (below the threshold of 3 claims for flagging).\\n   - **Fraud Score**: 0.2 (low risk).\\n   - **Warranty Validity**: Warranty is valid (time and mileage within limits).\\n   - **Invoice and VIN**: Invoice is present, and no mismatched VIN is reported.\\n   - **Conclusion**: No fraud indicators.\\n\\n6. **Escalation Rules**:\\n   - **Cost Threshold**: Total cost is $430 (below $1000 threshold for escalation).\\n   - **Borderline Case**: The claim involves a non-covered part (headlight), which makes it ambiguous and requires escalation.\\n   - **Conclusion**: **Escalation Required** due to non-covered part.\\n\\n---\\n\\n### **Red Flags/Violations**\\n1. **Part Not Covered**: The headlight is not listed as a covered part for four-wheelers under the warranty policy.\\n2. **Escalation Required**: The claim involves a non-covered part, which makes it a borderline case requiring escalation to HITL (Human-in-the-Loop) review.\\n\\n---\\n\\n### **Final Assessment**\\nThis claim has **violations** and must be **escalated** for further review.',\n",
       " 'decision': 'Escalate to HITL'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06e867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
